<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<sst xmlns="http://schemas.openxmlformats.org/spreadsheetml/2006/main" count="20875" uniqueCount="91"><si><t xml:space="preserve">longitude</t></si><si><t xml:space="preserve">latitude</t></si><si><t xml:space="preserve">housing_median_age</t></si><si><t xml:space="preserve">total_rooms</t></si><si><t xml:space="preserve">total_bedrooms</t></si><si><t xml:space="preserve">population</t></si><si><t xml:space="preserve">households</t></si><si><t xml:space="preserve">median_income</t></si><si><t xml:space="preserve">median_house_value</t></si><si><t xml:space="preserve">ocean_proximity</t></si><si><t xml:space="preserve">NEAR BAY</t></si><si><t xml:space="preserve">&lt;1H OCEAN</t></si><si><t xml:space="preserve">INLAND</t></si><si><t xml:space="preserve">NEAR OCEAN</t></si><si><t xml:space="preserve">ISLAND</t></si><si><t xml:space="preserve">0. to avoid replacing blank cells with 0s (which Microsoft Excel does by default), let us fill in blanks using the string “$BLANK”</t></si><si><t xml:space="preserve">1. We shuffle by adding a random index (column A) using Sheet &gt; Fill Cells &gt; Fill Random number. Then we sort by column A ascending.</t></si><si><t xml:space="preserve">index</t></si><si><t xml:space="preserve">2. Now we split into testing data and training data (discarding the unnecessary random index column).</t></si><si><t xml:space="preserve">Testing data</t></si><si><t xml:space="preserve">Total count</t></si><si><t xml:space="preserve">Test size</t></si><si><t xml:space="preserve">Test count</t></si><si><t xml:space="preserve">First test row</t></si><si><t xml:space="preserve">Last test row</t></si><si><t xml:space="preserve">Training data</t></si><si><t xml:space="preserve">3. We categorize the features of the training data. The dependent feature is “median_house_value“.&#10;We further categorize the independent features as numerical or categorical. Categorical features are further yet divided into ordinal and nominal.&#10;Ordinal features can be assigned a hierarchical score starting with 0, where an increase in that score is an increase in the feature. (Such is the case with ocean_proximity.&#10;Nominal features cannot be assigned score; we may think of these as names.</t></si><si><t xml:space="preserve">numerical</t></si><si><t xml:space="preserve">ordinal</t></si><si><t xml:space="preserve">dependent</t></si><si><t xml:space="preserve">4.0 Before the categorical features can be manipulated arithmetically, they must be encoded as numbers.&#10;Until then, we can at least count the occurrences and the total count, which allows us to see the total number of each.&#10;Let’s also calculate the frequency and standard error, which will allow us to create a bar chart later.</t></si><si><t xml:space="preserve">encoding</t></si><si><t xml:space="preserve">multiplicity</t></si><si><t xml:space="preserve">frequency</t></si><si><t xml:space="preserve">st.error</t></si><si><t xml:space="preserve">all</t></si><si><t xml:space="preserve">diff</t></si><si><t xml:space="preserve">4.1 Ordinal values are replaced with the assigned score. This is known as label encoding.</t></si><si><t xml:space="preserve">4.2 Nominal features are one-hot encoded. The trade-off is that we remove the risk of introducing a hierarchy by increasing the dimensionality of the data.&#10;In one-hot encoding, each of the categories becomes a new feature, assigned 1 if the original category matches the new feature or 0 otherwise, and the original feature is removed.&#10;The order of the new features does not matter because they are nominal, not ordinal.&#10;Also, we do this for all features except for one. Why? Because that last feature is not linearly independent from the rest, because one can calculate it as (1 - sum(other features)).&#10;Just be sure to document this as with everything.&#10;&#10;In our case, we did not have any nominal features.&#10;However, for example, assume we have data that includes fruits. Fruits cannot be scored objectively by this data. Thus, we use one-hot encoding.&#10;In this example of the one-hot encoding, we use alphabetical ordering, leaving out the pear category, but it could have been any of the others. Pears are the […,0,0,0,...] rows.</t></si><si><t xml:space="preserve">original data</t></si><si><t xml:space="preserve">count categories</t></si><si><t xml:space="preserve">one hot encoding</t></si><si><t xml:space="preserve">…</t></si><si><t xml:space="preserve">nominal</t></si><si><t xml:space="preserve">fruit</t></si><si><t xml:space="preserve">apple</t></si><si><t xml:space="preserve">orange</t></si><si><t xml:space="preserve">peach</t></si><si><t xml:space="preserve">pear</t></si><si><t xml:space="preserve">5.0 Let us consider the relation of each encoded feature to the dependent feature by plotting the relation.</t></si><si><t xml:space="preserve">5.1 We notice that longitude, latitude both seem to be periodic,&#10;but these with ocean_proximity each have very little relationship to the median_house_value because in each (x, y) relation, there may be many y values for each x.&#10;For total_rooms, total_bedrooms, population, households, median_income, we notice more settling away from 0. However, the values are more sparse. So let’s apply x’ := ln(x + 1), remembering $BLANK.&#10;Since we will be applying a linear regression, the objective of this step is to make each relation more linear, at least on average.</t></si><si><t xml:space="preserve">feature 2</t></si><si><t xml:space="preserve">feature 1</t></si><si><t xml:space="preserve">min</t></si><si><t xml:space="preserve">max</t></si><si><t xml:space="preserve">There is a strong negative correlation (&lt;= -0.9) between longitude, latitude.&#10;The pair of coordinates 41.95 °N, 124.35 °W and 32.54 °N, 114.31 °N correspond to the maximum, minimum and minimum, maximum of the latitude and longitude respectively.&#10;The area between these pairs of coordinates is California. Because of the reverse comma-shape of California, the further south you go, the further east you must also go.&#10;Thus, let’s treat the longitude as dependent on latitude. We may eliminate longitude as a feature.</t></si><si><t xml:space="preserve">There is a strong positive correlation (&gt;= +0.9) between total_rooms, total_bedrooms, population, households.&#10;Additionally, households has the highest correlation to the other features.&#10;Thus, let’s eliminate total_rooms, total_bedrooms, population as features.</t></si><si><t xml:space="preserve">6.1 We have chosen to remove latitude, total_rooms, total_bedrooms, population as features because they had strong positive (&gt;= +0.9) or negative (&lt;= -0.9) correlation.</t></si><si><t xml:space="preserve">7.0 We describe numerical data statistically.</t></si><si><t xml:space="preserve">percentile</t></si><si><t xml:space="preserve">count</t></si><si><t xml:space="preserve">mean</t></si><si><t xml:space="preserve">st.dev</t></si><si><t xml:space="preserve">low quartile</t></si><si><t xml:space="preserve">median</t></si><si><t xml:space="preserve">upper quartile</t></si><si><t xml:space="preserve">IQR</t></si><si><t xml:space="preserve">range</t></si><si><t xml:space="preserve">7.1 Minimal non-zero central inter-percentile range for histograms:&#10;We find histograms for the numerical features.&#10;First, for each feature, starting at the lower percentile with percent p = 25% and the matching upper percentile with percent (1 – p), we find the first non-zero range.&#10;Then scale by dividing by (2 – 4p).&#10;The interquartile range is referenced for comparison.</t></si><si><t xml:space="preserve">percent</t></si><si><t xml:space="preserve">lower percentile</t></si><si><t xml:space="preserve">upper percentile</t></si><si><t xml:space="preserve">nonzero range</t></si><si><t xml:space="preserve">inter percentile range</t></si><si><t xml:space="preserve">scaled</t></si><si><t xml:space="preserve">ref IQR</t></si><si><t xml:space="preserve">7.2 for the number of histogram bins, we use the Freedman-Diaconis’s choice formula&#10;        (range) ÷ (# bins)  = (bin width) ≈ 2(scaled IPR)(N^(-1/3))</t></si><si><t xml:space="preserve">scaled IPR</t></si><si><t xml:space="preserve">bin width</t></si><si><t xml:space="preserve"># bins</t></si><si><t xml:space="preserve">new bin width</t></si><si><t xml:space="preserve">7.3 For each of the numerical features, we number the bins according to 7.2, spacing them by the new bin width, starting from that feature’s minimal value.&#10;For each bin, then we count the number of occurrences at most that bin’s value, then we subtract the preceding value to find the multiplicity.&#10;Finally, the frequency is the multiplicity divided by the total number of occurrences of that feature.&#10;&#10;We also find the error limit to create the error bars.&#10;For these, we calculate the cumulative value as if the the feature was shifted down or up by the standard error respectively.&#10;As for the multiplicity, it is calculated:&#10;- for the lower limit, by the current +1 std error cumulative (less values will be &lt;= a shift up) minus the previous -1 std error, giving the lesser clearance, minus the mean multiplicty, then negated.&#10;- for the upper limit, by the current -1 std error cumulative (more values will be &lt;= a shift down) minus the previous +1 std error, giving the greater clearance, minus the mean multiplicity.&#10;The frequency is still calculated as the multiplicty divided by the total number of occurrences.</t></si><si><t xml:space="preserve">-1 std error</t></si><si><t xml:space="preserve">+1 std error</t></si><si><t xml:space="preserve">error -</t></si><si><t xml:space="preserve">error +</t></si><si><t xml:space="preserve">min value</t></si><si><t xml:space="preserve">std error</t></si><si><t xml:space="preserve">bin #</t></si><si><t xml:space="preserve">7.4 To graph the histogram, we graph the mean frequency of each numerical feature as a bar chart, using the bins as its x-axis labels.&#10;The error bar uses “error +” as the positive error, and “error -” as the negative error.&#10;Histograms have no spacing between each bar.&#10;&#10;To graph the bar chart, we graph the frequency of the ordinal feature, using the names and their encoding as the labels.&#10;The error bar uses just the standard error as both errors symmetrically.</t></si><si><t xml:space="preserve">s</t></si></sst>