<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<sst xmlns="http://schemas.openxmlformats.org/spreadsheetml/2006/main" count="4309" uniqueCount="104"><si><t xml:space="preserve">Let’s train the model and check how it fits the training data and add these to the summary.</t></si><si><t xml:space="preserve">change</t></si><si><t xml:space="preserve">param #0 name</t></si><si><t xml:space="preserve">param #0 value</t></si><si><t xml:space="preserve">param #1 name</t></si><si><t xml:space="preserve">param #1 value</t></si><si><t xml:space="preserve">encoding</t></si><si><t xml:space="preserve">replace missing</t></si><si><t xml:space="preserve">longitude</t></si><si><t xml:space="preserve">ocean_proximity</t></si><si><t xml:space="preserve">&lt;1H OCEAN</t></si><si><t xml:space="preserve">INLAND</t></si><si><t xml:space="preserve">ISLAND</t></si><si><t xml:space="preserve">NEAR BAY</t></si><si><t xml:space="preserve">latitude</t></si><si><t xml:space="preserve">housing_median_age</t></si><si><t xml:space="preserve">total_rooms</t></si><si><t xml:space="preserve">total_bedrooms</t></si><si><t xml:space="preserve">population</t></si><si><t xml:space="preserve">NEAR OCEAN</t></si><si><t xml:space="preserve">households</t></si><si><t xml:space="preserve">median_income</t></si><si><t xml:space="preserve">xy split</t></si><si><t xml:space="preserve">label</t></si><si><t xml:space="preserve">median_house_value</t></si><si><t xml:space="preserve">see G4:K9</t></si><si><t xml:space="preserve">normalization</t></si><si><t xml:space="preserve">center longitude</t></si><si><t xml:space="preserve">scale longitude</t></si><si><t xml:space="preserve">center latitude</t></si><si><t xml:space="preserve">scale latitude</t></si><si><t xml:space="preserve">center housing_median_age</t></si><si><t xml:space="preserve">scale housing_median_age</t></si><si><t xml:space="preserve">center total_rooms</t></si><si><t xml:space="preserve">scale total_rooms</t></si><si><t xml:space="preserve">center total_bedrooms</t></si><si><t xml:space="preserve">scale total_bedrooms</t></si><si><t xml:space="preserve">center population</t></si><si><t xml:space="preserve">scale population</t></si><si><t xml:space="preserve">center households</t></si><si><t xml:space="preserve">scale households</t></si><si><t xml:space="preserve">center median_income</t></si><si><t xml:space="preserve">scale median_income</t></si><si><t xml:space="preserve">center &lt;1H OCEAN</t></si><si><t xml:space="preserve">scale &lt;1H OCEAN</t></si><si><t xml:space="preserve">center INLAND</t></si><si><t xml:space="preserve">scale INLAND</t></si><si><t xml:space="preserve">center ISLAND</t></si><si><t xml:space="preserve">scale ISLAND</t></si><si><t xml:space="preserve">center NEAR BAY</t></si><si><t xml:space="preserve">scale NEAR BAY</t></si><si><t xml:space="preserve">weights</t></si><si><t xml:space="preserve">model</t></si><si><t xml:space="preserve">param name</t></si><si><t xml:space="preserve">param value</t></si><si><t xml:space="preserve">intercept</t></si><si><t xml:space="preserve">linear regression</t></si><si><t xml:space="preserve">see H29:H41</t></si><si><t xml:space="preserve">data fit</t></si><si><t xml:space="preserve">to training</t></si><si><t xml:space="preserve">percent MAE</t></si><si><t xml:space="preserve">percent RMSE</t></si><si><t xml:space="preserve">evaluation</t></si><si><t xml:space="preserve">classification</t></si><si><t xml:space="preserve">bottom 25%</t></si><si><t xml:space="preserve">top 50%</t></si><si><t xml:space="preserve">top 25%</t></si><si><t xml:space="preserve">missing feature</t></si><si><t xml:space="preserve">replacement</t></si><si><t xml:space="preserve">features</t></si><si><t xml:space="preserve">center</t></si><si><t xml:space="preserve">scale</t></si><si><t xml:space="preserve">Now that the training data has been cleaned. Let’s compare the percent MAE and RMSE to that of &#10;the fit to training data. We find that the difference is –0.23% and –0.30% respectively.&#10;Let’s say that if both overfits are at most +5.00%, the model is definitely not overfit to training data;&#10;and if either overfit is above +5.00%, it may suggest overfit to training data. (It may be that training&#10;and test were very similar. So the first case may warrant fitting to another set of test data.)</t></si><si><t xml:space="preserve">prediction</t></si><si><t xml:space="preserve">abs. error</t></si><si><t xml:space="preserve">sq. error</t></si><si><t xml:space="preserve">actual</t></si><si><t xml:space="preserve">mean</t></si><si><t xml:space="preserve">root</t></si><si><t xml:space="preserve">percent (fit to test)</t></si><si><t xml:space="preserve">fit to training data</t></si><si><t xml:space="preserve">overfit to training</t></si><si><t xml:space="preserve">In columns, F:H, we make the classifications. The classification is binary (TRUE or FALSE whether it&#10;belongs in the given class represented by that column).&#10;After classification, we find which predictions are correct (a prediction is correct if its binary value is&#10;the same as the actual class of the median_house_value).&#10;From these, we find true positives, values that are predicted to be in a given class, and that&#10;prediction is true (that is: (prediction=TRUE) AND correct).&#10;True negatives are values that are correct, but not true positives (#TN = #correct – #TP).&#10;False positives are values that are predicted to be correct, but are not true positives&#10;(#FP = #(prediction=TRUE) – #TP). &#10;False negatives are the values left after removing all correct values and all false positives from all the&#10;Predictions (#FN = #(all predictions) – #correct – #FP).&#10;(We could find TN, FP, FN the same way we found TP, but remembering these relations makes it&#10;faster and less cumbersome to find these values.)&#10;&#10;Finally, we can calculate the rates of accuracy (#correct/#(all predictions)), recall (#TP/(#TP + #FN))&#10;and precision (#TP/#(prediction=TRUE)).&#10;&#10;Accuracy tells us how many of our overall predictions are correct.&#10;Recall tells us how many members of each positive class we found.&#10;Precision tells us how many of our true predictions are also correct.</t></si><si><t xml:space="preserve">correct</t></si><si><t xml:space="preserve">true positive</t></si><si><t xml:space="preserve"># predictions</t></si><si><t xml:space="preserve">class</t></si><si><t xml:space="preserve">threshold</t></si><si><t xml:space="preserve">positive</t></si><si><t xml:space="preserve">true negative</t></si><si><t xml:space="preserve">false positive</t></si><si><t xml:space="preserve">false negative</t></si><si><t xml:space="preserve">accuracy</t></si><si><t xml:space="preserve">recall</t></si><si><t xml:space="preserve">precision</t></si><si><t xml:space="preserve">min, actual</t></si><si><t xml:space="preserve">max, actual</t></si><si><t xml:space="preserve">count</t></si><si><t xml:space="preserve">min chosen</t></si><si><t xml:space="preserve">max chosen</t></si><si><t xml:space="preserve">range, actual</t></si><si><t xml:space="preserve">range chosen</t></si><si><t xml:space="preserve">bin width</t></si><si><t xml:space="preserve"># bins</t></si></sst>